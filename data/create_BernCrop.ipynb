{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BernCrop File\n",
    "\n",
    "This notebook is used to create the HDF5 File for the BernCrop Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelhub import SHConfig\n",
    "import h5py\n",
    "import torch\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set default plt figsize to (12,6)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "\n",
    "from sentinelhub import (\n",
    "    BBox,\n",
    "    DataCollection,\n",
    "    MimeType,\n",
    "    MosaickingOrder,\n",
    "    SentinelHubRequest,\n",
    "    bbox_to_dimensions,\n",
    "    SentinelHubDownloadClient\n",
    ")\n",
    "\n",
    "download_log =''\n",
    "\n",
    "# Define the HDF5 file path and dataset parameters\n",
    "file_name_bern = r'..\\raw_data\\BernCrop\\BernCrop.hdf5'\n",
    "file_name_zueri = r'..\\raw_data\\ZueriCrop\\ZueriCrop.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_config(instance_id='8b5b5797-c269-42a4-b75a-dc1ed7e469a8',\n",
    "                  sh_client_id='f00771eb-624d-4106-973a-98963b395356',\n",
    "                  sh_client_secret='vnUy3ozu_s[z}W1O/>l6%U6GsfLfs]tLeS@jBs%!',\n",
    "                  sh_base_url='https://services.sentinel-hub.com',\n",
    "                  ):\n",
    "    config = SHConfig(\n",
    "        instance_id=instance_id,\n",
    "        sh_client_id=sh_client_id,\n",
    "        sh_client_secret=sh_client_secret,\n",
    "        sh_base_url=sh_base_url,\n",
    "    )\n",
    "    if not config.sh_client_id or not config.sh_client_secret:\n",
    "        print(\"Warning! To use Process API, please provide the credentials (OAuth client ID and client secret).\")\n",
    "    return config\n",
    "def create_bbox(coordinates:tuple, resolution:int=10, crs:int=32632):\n",
    "    resolution = resolution\n",
    "    bbox = BBox(bbox=coordinates, crs=crs)\n",
    "    bbox_size = bbox_to_dimensions(bbox, resolution=resolution)\n",
    "    print(f\"Image shape at {resolution} m resolution: {bbox_size} pixels\")\n",
    "    return bbox, bbox_size\n",
    "\n",
    "def create_time_slots(n_chunks :int = 365,\n",
    "                      start_date :datetime.datetime = datetime.datetime(2022, 1, 1,1,1,1,1),\n",
    "                      end_date :datetime.datetime = datetime.datetime(2022, 12, 31,1,1,1,1),verbose:bool =False):\n",
    "    tdelta = (end_date - start_date) / n_chunks\n",
    "    edges = [(start_date + i * tdelta).date().isoformat() for i in range(n_chunks)]\n",
    "    slots = [(edges[i], edges[i + 1]) for i in range(len(edges) - 1)]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"time windows:\\n\")\n",
    "        for slot in slots:\n",
    "            print(slot)\n",
    "    return slots\n",
    "\n",
    "def get_rgbnir_color_request(time_interval, coordinates:tuple):\n",
    "\n",
    "    evalscript_true_color = \"\"\"\n",
    "    //VERSION=3\n",
    "\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "                units: \"DN\"\n",
    "            }],\n",
    "        output: { // this defines the output image type\n",
    "        bands: 4, // the output of this evalscript will have RGB colors\n",
    "        sampleType: \"UINT16\" // raster format will be UINT16\n",
    "        }\n",
    "        };\n",
    "    }\n",
    "\n",
    "    function evaluatePixel(sample) {\n",
    "        return [sample.B04,sample.B03,sample.B02 , sample.B08];\n",
    "    }\n",
    "\"\"\"\n",
    "    bbox, bbox_size = create_bbox(coordinates)\n",
    "    return SentinelHubRequest(\n",
    "        evalscript=evalscript_true_color,\n",
    "        input_data=[\n",
    "            SentinelHubRequest.input_data(\n",
    "                data_collection=DataCollection.SENTINEL2_L2A,\n",
    "                time_interval=time_interval,\n",
    "                mosaicking_order=MosaickingOrder.LEAST_CC,\n",
    "            )\n",
    "        ],\n",
    "        responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n",
    "        bbox=bbox,\n",
    "        size=bbox_size,\n",
    "        config=create_config(),\n",
    "    )\n",
    "\n",
    "\n",
    "def get_coords():\n",
    "    coords = pd.read_csv(r'..\\raw_data\\BernCrop\\bern_bboxes_sentinel.csv',index_col=None)\n",
    "    coords = coords[coords['area'] >0]\n",
    "    coords= coords.iloc[:,1:5]\n",
    "    return coords\n",
    "\n",
    "\n",
    "def plot_seasons(dataset):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Sample data (replace this with your actual data)\n",
    "    # data= np.random.rand(287, 24, 24, 3, 10)  # 4 time steps, 3x3 pixels, 5 channels, 10 samples\n",
    "    data = torch.tensor(dataset).permute(1,2,3,4,0)\n",
    "    # Assuming you have information about which time steps belong to which seasons\n",
    "    # In this example, let's say time steps are equally divided into seasons\n",
    "    # Adjust this based on your actual data and seasons definition\n",
    "    seasons = ['Spring', 'Summer', 'Autumn', 'Winter']\n",
    "    time_steps_per_season = len(data) // len(seasons)\n",
    "\n",
    "    # Initialize histograms for each season\n",
    "    histograms = {season: np.zeros((24, 24, 9, 10), dtype=int) for season in seasons}\n",
    "\n",
    "    # Group data into histograms by season\n",
    "    for season, start_idx in zip(seasons, range(0, len(data), time_steps_per_season)):\n",
    "        end_idx = start_idx + time_steps_per_season\n",
    "        data_slice = data[start_idx:end_idx]\n",
    "        season_histogram = np.histogram(data_slice, bins=256, range=(0, 256))\n",
    "        histograms[season] = season_histogram\n",
    "\n",
    "    # Visualize histograms using bar charts\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle('Histograms for Different Seasons')\n",
    "\n",
    "    for i, season in enumerate(seasons):\n",
    "        ax = axes[i // 2, i % 2]\n",
    "        ax.set_title(season)\n",
    "        ax.bar(range(256), histograms[season][0], width=0.8, align='center', color='skyblue')\n",
    "        ax.set_xlabel('Channel Values')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Satellite Data from Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sentinel config\n",
    "config=create_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Bounding-Boxes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select coords\n",
    "coords = get_coords().iloc[0:1]\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords['x1'] - coords['x2']\n",
    "coords['x2'] = coords['x1'] + 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords['y1'] - coords['y2']\n",
    "coords['y2'] = coords['y1'] + 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords['y1'] - coords['y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords['x1'] - coords['x2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and put satellite data into hdf5 file\n",
    "\n",
    "We will download data from Sentinel-hub in the size 240x240 pixel and split them afterwards into 100 24x24 pixel fields.\n",
    "These fields are then stored in the hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture download_log --no-stderr\n",
    "print(f\"Start Download at: {datetime.datetime.today()}\")\n",
    "\n",
    "temp_results_tensor = []\n",
    "twoforty_tensor = False\n",
    "for i,coordinates in coords.iterrows():\n",
    "    print(f'started downloading bounding_box: {coordinates} with index:{i}')\n",
    "    \n",
    "    # assert bbox_to_dimensions(BBox(bbox=tuple(coordinates), crs=32632), resolution=10) == (240,240)\n",
    "    \n",
    "    list_of_requests = [get_rgbnir_color_request(time_interval, tuple(coordinates)) for time_interval in create_time_slots(142)]\n",
    "    list_of_requests = [request.download_list[0] for request in list_of_requests]\n",
    "    \n",
    "    # download data with multiple threads\n",
    "    download_data_timesteps = SentinelHubDownloadClient(config=config).download(list_of_requests, max_threads=20)\n",
    "    non_zero_downloads = torch.tensor([v for i,v in enumerate(download_data_timesteps) if download_data_timesteps[i].sum() > 0]).unsqueeze(0)\n",
    "    temp_results_tensor.append(non_zero_downloads)\n",
    "\n",
    "result_tensor = torch.cat(temp_results_tensor, dim=0)\n",
    "print(f\"Stopped Download at: {datetime.datetime.today()}\")\n",
    "\n",
    "print(f\"Start Reshape Data at: {datetime.datetime.today()}\")\n",
    "\n",
    "# Reshape the original tensor into the target shape\n",
    "# result_shape = (result_tensor.shape[0]*100, result_tensor.shape[1], 24, 24, result_tensor.shape[4])\n",
    "# result_tensor = result_tensor.reshape(result_shape)\n",
    "print(f\"Stopped Reshape at: {datetime.datetime.today()}\")\n",
    "\n",
    "\n",
    "print(f\"Start Saving Data at: {datetime.datetime.today()}\")\n",
    "\n",
    "\n",
    "dataset_data_name = \"data\"\n",
    "data_shape = result_tensor.shape\n",
    "\n",
    "\n",
    "with h5py.File(file_name_bern, 'a') as hf:\n",
    "    # Check if the dataset already exists\n",
    "    if dataset_data_name in hf:\n",
    "        dataset = hf[dataset_data_name]\n",
    "    else:\n",
    "        dtype = \"float32\"  # Use the appropriate data type for your data\n",
    "        dataset = hf.create_dataset(dataset_data_name, shape=(0,) + data_shape[1:], dtype=dtype, maxshape=(None,) + data_shape[1:])\n",
    "        \n",
    "    current_size = dataset.shape[0]\n",
    "    new_size = current_size + result_tensor.shape[0]\n",
    "    # Resize the dataset to accommodate the new batch\n",
    "    dataset.resize(new_size, axis=0)\n",
    "    # Append the new batch to the dataset\n",
    "    dataset[current_size:new_size, :] = result_tensor\n",
    "\n",
    "print(f\"Stopped Saving Data at: {datetime.datetime.today()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Data to HDF5\n",
    "Now we add the label data to the 'gt' hdf5 file dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_label_name = \"gt\"\n",
    "#TODO: define label_tensor\n",
    "label_shape = result_tensor[:,-1,:,:,-1].shape\n",
    "label_tensor = result_tensor[:,-1,:,:,-1]\n",
    "\n",
    "with h5py.File(file_name_bern, 'a') as hf:    \n",
    "    # Check if the dataset already exists\n",
    "    if dataset_label_name in hf:\n",
    "        dataset = hf[dataset_label_name]\n",
    "    else:\n",
    "        dtype = \"float32\"  # Use the appropriate data type for your data\n",
    "        dataset = hf.create_dataset(dataset_label_name, shape=(0,) + label_shape[1:], dtype=dtype, maxshape=(None,) + label_shape[1:])\n",
    "        \n",
    "    current_size = dataset.shape[0]\n",
    "    new_size = current_size + label_tensor.shape[0]\n",
    "    # Resize the dataset to accommodate the new batch\n",
    "    dataset.resize(new_size, axis=0)\n",
    "    # Append the new batch to the dataset\n",
    "    dataset[current_size:new_size, :] = label_tensor\n",
    "\n",
    "print(f\"Stopped Saving Data at: {datetime.datetime.today()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(file_name_bern, \"r\") as file:\n",
    "    # Check if the \"data\" dataset exists in the file\n",
    "    if \"data\" in file:\n",
    "        # Access the dataset and read its contents into a NumPy array\n",
    "        dataset_b = file[\"data\"][:]\n",
    "    else:\n",
    "        print(\"Dataset 'data' not found in the HDF5 file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_b[:,:,:,:,0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seasons(dataset_b[:,:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seasons(dataset_b[:,:,:,:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seasons(dataset_b[:,:,:,:,1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seasons(dataset_b[:,:,:,:,2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seasons(dataset_b[:,:,:,:,3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(file_name_zueri, \"r\") as file:\n",
    "    # Check if the \"data\" dataset exists in the file\n",
    "    if \"data\" in file:\n",
    "        # Access the dataset and read its contents into a NumPy array\n",
    "        dataset_z = file[\"data\"][0:1000]\n",
    "    else:\n",
    "        print(\"Dataset 'data' not found in the HDF5 file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_z.shape\n",
    "plot_seasons(dataset_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(file_name_bern, \"r\") as file:\n",
    "    # Check if the \"data\" dataset exists in the file\n",
    "    if \"data\" in file:\n",
    "        # Access the dataset and read its contents into a NumPy array\n",
    "        dataset = file[\"gt\"][:]\n",
    "    else:\n",
    "        print(\"Dataset 'data' not found in the HDF5 file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgroLuege--zjmSdF3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
