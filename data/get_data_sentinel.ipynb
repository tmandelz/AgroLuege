{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelhub import SHConfig\n",
    "import h5py\n",
    "import torch\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set default plt figsize to (12,6)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "\n",
    "from sentinelhub import (\n",
    "    BBox,\n",
    "    DataCollection,\n",
    "    MimeType,\n",
    "    MosaickingOrder,\n",
    "    SentinelHubRequest,\n",
    "    bbox_to_dimensions,\n",
    "    SentinelHubDownloadClient\n",
    ")\n",
    "\n",
    "download_log =''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_config(instance_id='8b5b5797-c269-42a4-b75a-dc1ed7e469a8',\n",
    "                  sh_client_id='f00771eb-624d-4106-973a-98963b395356',\n",
    "                  sh_client_secret='vnUy3ozu_s[z}W1O/>l6%U6GsfLfs]tLeS@jBs%!',\n",
    "                  sh_base_url='https://services.sentinel-hub.com',\n",
    "                  ):\n",
    "    config = SHConfig(\n",
    "        instance_id=instance_id,\n",
    "        sh_client_id=sh_client_id,\n",
    "        sh_client_secret=sh_client_secret,\n",
    "        sh_base_url=sh_base_url,\n",
    "    )\n",
    "    if not config.sh_client_id or not config.sh_client_secret:\n",
    "        print(\"Warning! To use Process API, please provide the credentials (OAuth client ID and client secret).\")\n",
    "    return config\n",
    "def create_bbox(coordinates:tuple, resolution:int=10, crs:int=32632):\n",
    "    resolution = resolution\n",
    "    bbox = BBox(bbox=coordinates, crs=crs)\n",
    "    bbox_size = bbox_to_dimensions(bbox, resolution=resolution)\n",
    "    print(f\"Image shape at {resolution} m resolution: {bbox_size} pixels\")\n",
    "    return bbox, bbox_size\n",
    "\n",
    "def create_time_slots(n_chunks :int = 365,\n",
    "                      start_date :datetime.datetime = datetime.datetime(2022, 1, 1,1,1,1,1),\n",
    "                      end_date :datetime.datetime = datetime.datetime(2022, 12, 31,1,1,1,1),verbose:bool =False):\n",
    "    tdelta = (end_date - start_date) / n_chunks\n",
    "    edges = [(start_date + i * tdelta).date().isoformat() for i in range(n_chunks)]\n",
    "    slots = [(edges[i], edges[i + 1]) for i in range(len(edges) - 1)]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"time windows:\\n\")\n",
    "        for slot in slots:\n",
    "            print(slot)\n",
    "    return slots\n",
    "\n",
    "def get_rgbnir_color_request(time_interval, coordinates:tuple):\n",
    "\n",
    "    evalscript_true_color = \"\"\"\n",
    "    //VERSION=3\n",
    "\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "            }],\n",
    "            output: {\n",
    "                bands: 4\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "\n",
    "    function evaluatePixel(sample) {\n",
    "        return [sample.B04, sample.B03, sample.B02 , sample.B08];\n",
    "    }\n",
    "\"\"\"\n",
    "    bbox, bbox_size = create_bbox(coordinates)\n",
    "    return SentinelHubRequest(\n",
    "        evalscript=evalscript_true_color,\n",
    "        input_data=[\n",
    "            SentinelHubRequest.input_data(\n",
    "                data_collection=DataCollection.SENTINEL2_L2A,\n",
    "                time_interval=time_interval,\n",
    "                mosaicking_order=MosaickingOrder.LEAST_CC,\n",
    "            )\n",
    "        ],\n",
    "        responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n",
    "        bbox=bbox,\n",
    "        size=bbox_size,\n",
    "        config=create_config(),\n",
    "    )\n",
    "\n",
    "\n",
    "def get_coords():\n",
    "    coords = pd.read_csv(r'..\\raw_data\\BernCrop\\bern_bboxes_sentinel.csv',index_col=None)\n",
    "    coords = coords[coords['area'] >0]\n",
    "    coords= coords.iloc[:,1:5]\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=create_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select coords\n",
    "coords = get_coords().iloc[0:1]\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture download_log --no-stderr\n",
    "print(f\"Start Download at: {datetime.datetime.today()}\")\n",
    "\n",
    "temp_results_tensor = []\n",
    "twoforty_tensor = False\n",
    "for i,coordinates in coords.iterrows():\n",
    "    print(f'started downloading bounding_box: {coordinates} with index:{i}')\n",
    "    \n",
    "    assert bbox_to_dimensions(BBox(bbox=tuple(coordinates), crs=32632), resolution=10) == (240,240)\n",
    "    \n",
    "    list_of_requests = [get_rgbnir_color_request(time_interval, tuple(coordinates)) for time_interval in create_time_slots()]\n",
    "    list_of_requests = [request.download_list[0] for request in list_of_requests]\n",
    "    \n",
    "    # download data with multiple threads\n",
    "    download_data_timesteps = SentinelHubDownloadClient(config=config).download(list_of_requests, max_threads=20)\n",
    "    non_zero_downloads = torch.tensor([v for i,v in enumerate(download_data_timesteps) if download_data_timesteps[i].sum() > 0]).unsqueeze(0)\n",
    "    temp_results_tensor.append(non_zero_downloads)\n",
    "\n",
    "result_tensor = torch.cat(temp_results_tensor, dim=0)\n",
    "print(f\"Stopped Download at: {datetime.datetime.today()}\")\n",
    "\n",
    "print(f\"Start Reshape Data at: {datetime.datetime.today()}\")\n",
    "\n",
    "# Reshape the original tensor into the target shape\n",
    "result_shape = (result_tensor.shape[0]*100, result_tensor.shape[1], 24, 24, result_tensor.shape[4])\n",
    "result_tensor = result_tensor.reshape(result_shape)\n",
    "print(f\"Stopped Reshape at: {datetime.datetime.today()}\")\n",
    "\n",
    "\n",
    "print(f\"Start Saving Data at: {datetime.datetime.today()}\")\n",
    "\n",
    "# Define the HDF5 file path and dataset parameters\n",
    "file_name = r'..\\raw_data\\BernCrop\\bern_bbox.hdf5'\n",
    "dataset_data_name = \"data\"\n",
    "dataset_label_name = \"gt\"\n",
    "data_shape = result_tensor.shape\n",
    "#TODO: define label_tensor\n",
    "label_shape = result_tensor[:,-1,:,:,-1].shape\n",
    "label_tensor = result_tensor[:,-1,:,:,-1]\n",
    "\n",
    "\n",
    "with h5py.File(file_name, 'a') as hf:\n",
    "    # Check if the dataset already exists\n",
    "    if dataset_data_name in hf:\n",
    "        dataset = hf[dataset_data_name]\n",
    "    else:\n",
    "        dtype = \"float32\"  # Use the appropriate data type for your data\n",
    "        dataset = hf.create_dataset(dataset_data_name, shape=(0,) + data_shape[1:], dtype=dtype, maxshape=(None,) + data_shape[1:])\n",
    "        \n",
    "    current_size = dataset.shape[0]\n",
    "    new_size = current_size + result_tensor.shape[0]\n",
    "    # Resize the dataset to accommodate the new batch\n",
    "    dataset.resize(new_size, axis=0)\n",
    "    # Append the new batch to the dataset\n",
    "    dataset[current_size:new_size, :] = result_tensor\n",
    "    \n",
    "    # Check if the dataset already exists\n",
    "    if dataset_label_name in hf:\n",
    "        dataset = hf[dataset_label_name]\n",
    "    else:\n",
    "        dtype = \"float32\"  # Use the appropriate data type for your data\n",
    "        dataset = hf.create_dataset(dataset_label_name, shape=(0,) + label_shape[1:], dtype=dtype, maxshape=(None,) + label_shape[1:])\n",
    "        \n",
    "    current_size = dataset.shape[0]\n",
    "    new_size = current_size + label_tensor.shape[0]\n",
    "    # Resize the dataset to accommodate the new batch\n",
    "    dataset.resize(new_size, axis=0)\n",
    "    # Append the new batch to the dataset\n",
    "    dataset[current_size:new_size, :] = label_tensor\n",
    "\n",
    "print(f\"Stopped Saving Data at: {datetime.datetime.today()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = r'..\\raw_data\\BernCrop\\bern_bbox.hdf5'  # Replace with the name of your HDF5 file\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(file_name, \"r\") as file:\n",
    "    # Check if the \"data\" dataset exists in the file\n",
    "    if \"data\" in file:\n",
    "        # Access the dataset and read its contents into a NumPy array\n",
    "        dataset = file[\"data\"][:]\n",
    "    else:\n",
    "        print(\"Dataset 'data' not found in the HDF5 file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = r'..\\raw_data\\BernCrop\\bern_bbox.hdf5'  # Replace with the name of your HDF5 file\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(file_name, \"r\") as file:\n",
    "    # Check if the \"data\" dataset exists in the file\n",
    "    if \"data\" in file:\n",
    "        # Access the dataset and read its contents into a NumPy array\n",
    "        dataset = file[\"gt\"][:]\n",
    "    else:\n",
    "        print(\"Dataset 'data' not found in the HDF5 file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dataset.shape[0]):\n",
    "    title_pre = f'Picture_{i} '\n",
    "    for j in range(dataset.shape[1]):\n",
    "        if j in [1,70,140,280]:\n",
    "            if j == 1:\n",
    "                title = 'Winter'\n",
    "            elif j == 70:\n",
    "                title = 'Spring'\n",
    "            elif j == 140:\n",
    "                title = 'Summer'\n",
    "            elif j == 280:\n",
    "                title = 'Autumn'\n",
    "\n",
    "            image = torch.tensor(dataset[i, j,:, :, 0:3])\n",
    "            plt.axis('off')\n",
    "            plt.title(title_pre+title)\n",
    "            plt.imshow(image.permute(0, 1, 2).numpy())\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgroLuege--zjmSdF3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
