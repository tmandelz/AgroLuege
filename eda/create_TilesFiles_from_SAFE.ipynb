{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "117f5d6c-dd4c-4c7e-a87c-0a003cbb70fe",
   "metadata": {},
   "source": [
    "# Create bernCrop Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a41e2-811f-4041-a491-86537f052f98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load required modules\n",
    "import cv2\n",
    "import eodal\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import utm\n",
    "import torch\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from pathlib import Path\n",
    "from eodal.core.sensors import Sentinel2\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from eodal.config import get_settings\n",
    "\n",
    "# make plots larger by default\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "print('eodal version: {}'.format(eodal.__version__))\n",
    "\n",
    "# we need to tell EOdal that we work using a local data source\n",
    "settings = get_settings()\n",
    "settings.USE_STAC = False\n",
    "\n",
    "\n",
    "output_shapefile_path_BERN = f\"../raw_data/LANDKULT/data/BERN_big_bbox.shp\"\n",
    "output_shapefile_path_tiles =f\"../raw_data/LANDKULT/data/tiles/\"\n",
    "output_shapefile_path_tile_T32TLT = f\"../raw_data/LANDKULT/data/tiles/T32TLT.shp\"\n",
    "output_shapefile_path_tile_T32TLS = f\"../raw_data/LANDKULT/data/tiles/T32TLS.shp\"\n",
    "output_shapefile_path_tile_T32TMT = f\"../raw_data/LANDKULT/data/tiles/T32TMT.shp\"\n",
    "output_shapefile_path_tile_T32TMS = f\"../raw_data/LANDKULT/data/tiles/T32TMS.shp\"\n",
    "shapefile_path_landkult = '../raw_data/LANDKULT/data/LANDKULT_NUTZFL.shp'\n",
    "output_shapefile_path_landkult = '../raw_data/LANDKULT/data/LANDKULT_NUTZFL_bern_bbox.shp'\n",
    "output_shapefile_path_landkult_short = '../raw_data/LANDKULT/data/LANDKULT_NUTZFL_short_bern_bbox.shp'\n",
    "output_shapefile_path_landkult_short_eodal = 'D:/Temp/AgroLuege/raw_data/LANDKULT/data/LANDKULT_NUTZFL_short_bern_bbox.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1488fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coordinates_to_utm(coordinates):\n",
    "    utm_coordinates = []\n",
    "    for lat, lon in coordinates:\n",
    "        utm_coordinate = utm.from_latlon(lat, lon)\n",
    "        utm_coordinates.append((utm_coordinate[0], utm_coordinate[1], utm_coordinate[2], utm_coordinate[3]))\n",
    "    return utm_coordinates\n",
    "\n",
    "def get_adjacent_points(utm_coordinates):\n",
    "    adjacent_coordinates_beneath = []\n",
    "    for easting, northing, zone_number, zone_letter in utm_coordinates:\n",
    "        # Point beneath\n",
    "        right_point = utm.to_latlon(easting - 100000, northing, zone_number, zone_letter)\n",
    "        adjacent_coordinates_beneath.append(right_point)\n",
    "    return adjacent_coordinates_beneath\n",
    "\n",
    "def get_bern_bbox():\n",
    "    # Define the coordinates\n",
    "    x1, y1, x2, y2 = 361630.,5140066., 416830.,  5238466.\n",
    "\n",
    "    # Create a GeoDataFrame with a single Point geometry\n",
    "    geometry = Polygon([(x1, y1), (x2, y1), (x2, y2), (x1, y2)])\n",
    "    gdf_bern = gpd.GeoDataFrame(geometry=[geometry], crs=\"EPSG:32632\")\n",
    "    # Save the GeoDataFrame to a shapefile\n",
    "    gdf_bern.to_file(output_shapefile_path_BERN)\n",
    "    return gdf_bern\n",
    "\n",
    "\n",
    "def get_tile_folder_path(data_dir):\n",
    "    paths = []\n",
    "    def get_subdirectories(path, depth=0, max_depth=0):\n",
    "        if depth > max_depth:\n",
    "            return\n",
    "\n",
    "        subdirectories = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "        for subdir in subdirectories:\n",
    "            subdir_path = os.path.join(path, subdir)\n",
    "            if subdir_path.endswith('.SAFE'):\n",
    "                paths.append(subdir_path)\n",
    "            get_subdirectories(subdir_path, depth + 1, max_depth)\n",
    "    get_subdirectories(data_dir)\n",
    "    # sort the paths by timestamp\n",
    "    paths.sort()\n",
    "    return paths\n",
    "\n",
    "\n",
    "def make_polygon_within(polygon1, polygon2):\n",
    "    return  polygon1.intersection(polygon2)\n",
    "\n",
    "\n",
    "def read_tile_data_from_safe(tile_paths, coords, tile, band_selection = ['B02', 'B03', 'B04', 'B08'], polygon_size = 240*240):\n",
    "    # TODO: all file paths please\n",
    "    tile_shape_path = output_shapefile_path_tiles+f'{tile}.shp'\n",
    "    tile_gdf = gpd.read_file(tile_shape_path)\n",
    "    for path_SAFE in tile_paths[0:2]:\n",
    "        vector_feature_data = []\n",
    "        for i,coordinates in coords.iterrows():\n",
    "            x1, y1, x2, y2 = coordinates.iloc[:4].tolist()\n",
    "            polygon = Polygon([(x1, y1), (x2, y1), (x2, y2), (x1, y2)])\n",
    "            polygon_gdf = gpd.GeoDataFrame(geometry=[polygon],crs='EPSG:32632')\n",
    "\n",
    "            polygon_clipped_coords = make_polygon_within(tile_gdf.geometry[0],polygon_gdf.geometry[0])\n",
    "            polygon_clipped_coords_df = gpd.GeoDataFrame(geometry=[polygon_clipped_coords],crs='EPSG:32632')\n",
    "            intersection_area = polygon_clipped_coords_df.geometry.iloc[0].area\n",
    "\n",
    "            if intersection_area == polygon_size:\n",
    "                # print(f'started bounding_box: {coordinates} with index:{i} at timestamp {path_SAFE}')\n",
    "                # print(\"Intersection Area:\", polygon_clipped_coords_df.geometry.iloc[0].area)\n",
    "\n",
    "                try:\n",
    "                    # read data from .SAFE dataset for the selected AOI and spectral bands\n",
    "                    handler = Sentinel2.from_safe(\n",
    "                        in_dir=Path(path_SAFE),\n",
    "                        vector_features=polygon_clipped_coords_df,\n",
    "                        band_selection=band_selection,\n",
    "                        apply_scaling=False\n",
    "                    )\n",
    "                except ValueError as ex:\n",
    "                    print(f'error:\\n{ex} but continue anyway\\n Path:{path_SAFE}')\n",
    "                    #save wrong polygons\n",
    "                    polygon_clipped_coords_df.to_csv(f'./errors/error_polygon_{i}_{tile}.csv')\n",
    "                    continue\n",
    "                # ignore the value if its blackfilled\n",
    "                if handler.is_blackfilled == True:\n",
    "                    print(f\"Skip is blackfilled: {path_SAFE}\")\n",
    "                    polygon_clipped_coords_df\n",
    "\n",
    "                    continue\n",
    "                # first resample the spectral bands using bicubic interpolation\n",
    "                handler.resample(\n",
    "                    target_resolution=10,\n",
    "                    interpolation_method=cv2.INTER_NEAREST_EXACT,\n",
    "                    inplace=True\n",
    "                )\n",
    "\n",
    "                # create a numpy array and remove last band\n",
    "                #TODO: check if this is okay, we select 24x24 but the outcome is 26x26\n",
    "                # timestamp_tile_data = [handler.to_xarray().to_numpy()[0:4,0:24,0:24]]\n",
    "                single_feature_data = np.array(handler.to_xarray().to_numpy()[0:4])\n",
    "                vector_feature_data.append(single_feature_data)\n",
    "                # save tile data\n",
    "            else:\n",
    "                # print(\"Intersection Area:\", polygon_clipped_coords_df.geometry.iloc[0].area)\n",
    "                # print('edge case intersection not fully, is therefore ignored for this tile.')\n",
    "                continue\n",
    "            # save after each timestamp\n",
    "        \n",
    "        if len(vector_feature_data) > 0:\n",
    "            vector_feature_data = np.array(vector_feature_data)\n",
    "            print(vector_feature_data.shape)\n",
    "            save_tile_data(vector_feature_data, tile)\n",
    "            save_ground_truth_data(i,tile)\n",
    "\n",
    "def save_tile_data(tile_array, tile,dataset_data_name=\"data\",add_axis=True):\n",
    "    file_name_tile = f'../raw_data/BernCrop/tiles/{tile}.hdf5'\n",
    "    if add_axis:\n",
    "        tile_array=tile_array[np.newaxis,:]\n",
    "    data_shape = tile_array.shape\n",
    "    print(data_shape)\n",
    "\n",
    "\n",
    "    with h5py.File(file_name_tile, 'a') as hf:\n",
    "        # Check if the dataset already exists\n",
    "        if dataset_data_name in hf:\n",
    "            dataset = hf[dataset_data_name]\n",
    "        else:\n",
    "            dtype = \"float32\"  # Use the appropriate data type for your data\n",
    "            dataset = hf.create_dataset(dataset_data_name, shape=(0,) + data_shape[1:], dtype=dtype, maxshape=(None,) + data_shape[1:])\n",
    "            \n",
    "        current_size = dataset.shape[0]\n",
    "        new_size = current_size + tile_array.shape[0]\n",
    "        # Resize the dataset to accommodate the new batch\n",
    "        dataset.resize(new_size, axis=0)\n",
    "        # Append the new batch to the dataset\n",
    "        dataset[current_size:new_size, :] = tile_array\n",
    "\n",
    "def save_label_data(index_data,tile):\n",
    "    # Specify the file path\n",
    "    file_path = r'..\\raw_data\\BernCrop\\tensor_label.pt'\n",
    "    # Load the tensor from the file\n",
    "    all_labels = torch.load(file_path)\n",
    "    data_label = all_labels[index_data]\n",
    "\n",
    "    save_tile_data(data_label,tile,'gt')\n",
    "\n",
    "def save_field_label_data(index_data,tile):\n",
    "    # Specify the file path\n",
    "    file_path = r'..\\raw_data\\BernCrop\\tensor_field.pt'\n",
    "\n",
    "    # Load the tensor from the file\n",
    "    all_labels = torch.load(file_path)\n",
    "    data_label = all_labels[index_data]\n",
    "\n",
    "    save_tile_data(data_label,tile,'gt_instance')\n",
    "\n",
    "def save_ground_truth_data(index_data,tile):\n",
    "\n",
    "    save_label_data(index_data,tile)\n",
    "    save_field_label_data(index_data,tile)\n",
    "    \n",
    "\n",
    "def read_tile_data(tile,dataset_data_name=\"data\"):\n",
    "    filename_tile = f'../raw_data/BernCrop/tiles/{tile}.hdf5'\n",
    "    # Open the HDF5 file in read mode\n",
    "    with h5py.File(filename_tile, \"r\") as file:\n",
    "        # Check if the \"data\" dataset exists in the file\n",
    "        if dataset_data_name in file:\n",
    "            # Access the dataset and read its contents into a NumPy array\n",
    "            dataset = file[dataset_data_name][:]\n",
    "        else:\n",
    "            print(f\"Dataset {dataset_data_name} not found in the HDF5 file.\")\n",
    "    return dataset\n",
    "\n",
    "def get_coords(tile=None,is_short=False):\n",
    "    if tile == None:\n",
    "        coords = pd.read_csv(r'..\\raw_data\\BernCrop\\bboxes_sentinel_24x24.csv',index_col=None)\n",
    "        coords= coords.iloc[:, 1:5]\n",
    "    else:\n",
    "        if is_short:\n",
    "            coords = pd.read_csv(fr'..\\raw_data\\BernCrop\\bboxes_sentinel_24x24_{tile}_short.csv',index_col=None)\n",
    "        else:\n",
    "            coords = pd.read_csv(fr'..\\raw_data\\BernCrop\\bboxes_sentinel_24x24_{tile}.csv',index_col=None)\n",
    "        coords= coords.iloc[:, 1:5]\n",
    "    return coords\n",
    "\n",
    "\n",
    "def stack_sample_tiles(tile_array,minimal_t=10,):\n",
    "    if minimal_t != None:\n",
    "        tile_array = np.transpose(tile_array, (0, 1, 3, 4,2))\n",
    "        sampled_indices = np.random.choice(tile_array.shape[1], size=minimal_t, replace=False)\n",
    "        tile_array = tile_array[:,sampled_indices]\n",
    "        print(tile_array.shape)\n",
    "    # tile_array_return = np.expand_dims(tile_array, axis=0)\n",
    "    print(tile_array.shape)\n",
    "    return tile_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_T32TLT = [(6.3279, 46.8356), (7.8166, 46.8356), (7.8166, 47.8474), (6.3279, 47.8474)]\n",
    "polygon_T32TLT = Polygon(coordinates_T32TLT)\n",
    "gdf_T32TLT = gpd.GeoDataFrame(geometry=[polygon_T32TLT],crs=\"EPSG:4326\").to_crs(crs=\"EPSG:32632\")\n",
    "gdf_T32TLT.to_file(output_shapefile_path_tile_T32TLT)\n",
    "\n",
    "utm_coordinates_T32TLS = convert_coordinates_to_utm(coordinates_T32TLT)\n",
    "coordinates_T32TLS = get_adjacent_points(utm_coordinates_T32TLS)\n",
    "polygon_T32TLS = Polygon(coordinates_T32TLS)\n",
    "gdf_T32TLS = gpd.GeoDataFrame(geometry=[polygon_T32TLS],crs=\"EPSG:4326\").to_crs(crs=\"EPSG:32632\")\n",
    "gdf_T32TLS.to_file(output_shapefile_path_tile_T32TLS)\n",
    "\n",
    "coordinates_T32TMT = [(7.6629, 46.8582), (9.1305, 46.8582), (9.1305, 47.8536), (7.6629, 47.8536)]\n",
    "polygon_T32TMT = Polygon(coordinates_T32TMT)\n",
    "gdf_T32TMT = gpd.GeoDataFrame(geometry=[polygon_T32TMT],crs=\"EPSG:4326\").to_crs(crs=\"EPSG:32632\")\n",
    "gdf_T32TMT.to_file(output_shapefile_path_tile_T32TMT)\n",
    "\n",
    "utm_coordinates_T32TMS= convert_coordinates_to_utm(coordinates_T32TMT)\n",
    "coordinates_T32TMS = get_adjacent_points(utm_coordinates_T32TMS)\n",
    "polygon_T32TMS = Polygon(coordinates_T32TMS)\n",
    "gdf_T32TMS = gpd.GeoDataFrame(geometry=[polygon_T32TMS],crs=\"EPSG:4326\").to_crs(crs=\"EPSG:32632\")\n",
    "gdf_T32TMS.to_file(output_shapefile_path_tile_T32TMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b023a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiles = ['T32TLT','T32TLS','T32TMT','T32TMS']\n",
    "# for tile in tiles:\n",
    "#     tile_shape_path = output_shapefile_path_tiles+f'{tile}.shp'\n",
    "#     tile_gdf = gpd.read_file(tile_shape_path,crs='EPSG:32632')\n",
    "\n",
    "#     coords = pd.read_csv(r'..\\raw_data\\BernCrop\\bboxes_sentinel_24x24.csv',index_col=[0])\n",
    "#     coords.sort_index(ascending=True)\n",
    "#     geometry = [Polygon([(x1, y1), (x2, y1), (x2, y2), (x1, y2)]) for x1, y1,x2,y2 in zip(coords['x1'], coords['y1'],coords['x2'], coords['y2'])]\n",
    "#     gdf = gpd.GeoDataFrame(coords, geometry=geometry)\n",
    "#     completely_inside_polygons = gdf[gdf.geometry.within(tile_gdf.geometry.iloc[0])]\n",
    "#     completely_inside_polygons = completely_inside_polygons[completely_inside_polygons.geometry.within(get_bern_bbox().geometry.iloc[0])]\n",
    "#     completely_inside_polygons.to_csv(fr'../raw_data/BernCrop/bboxes_sentinel_24x24_{tile}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8789fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tile in tiles:\n",
    "#     tile_paths = get_tile_folder_path(Path('E:/S2_Data_CH22/' + str(tile)))\n",
    "#     for i in tile_paths:\n",
    "#         # Path to your XML file\n",
    "#         xml_file_path = i+\"\\INSPIRE.xml\"\n",
    "#         print(xml_file_path)\n",
    "\n",
    "#         # Parse the XML file\n",
    "#         tree = ET.parse(xml_file_path)\n",
    "#         root = tree.getroot()\n",
    "\n",
    "#         # Define the namespace dictionary\n",
    "#         namespace = {\n",
    "#             \"gmd\": \"http://www.isotc211.org/2005/gmd\",\n",
    "#             \"gco\": \"http://www.isotc211.org/2005/gco\"\n",
    "#         }\n",
    "\n",
    "#         # Define the XPath expression with namespaces\n",
    "#         xpath_expression = \"./gmd:identificationInfo/gmd:MD_DataIdentification/gmd:abstract/gco:CharacterString\"\n",
    "\n",
    "#         # Find the element using find() with the namespace\n",
    "#         abstract_element = root.find(xpath_expression, namespaces=namespace)\n",
    "\n",
    "#         # Extract the text content\n",
    "#         abstract_text = abstract_element.text if abstract_element is not None else None\n",
    "\n",
    "#         abstract_text= abstract_text.replace(' ',',')\n",
    "#         coordinates_list_str = abstract_text.split(',')\n",
    "#         coordinates_list_str = [coord for coord in coordinates_list_str if coord]\n",
    "#         coordinates_list = [(float(coordinates_list_str[i]), float(coordinates_list_str[i + 1])) for i in range(0, len(coordinates_list_str), 2)]\n",
    "#         coordinates_list\n",
    "#         polygon = Polygon(coordinates_list)\n",
    "\n",
    "#         gdf = gpd.GeoDataFrame(geometry=[polygon])\n",
    "#         gdf.plot()\n",
    "#         plt.show()\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79866c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords= get_coords()\n",
    "# # Create a GeoPandas GeoDataFrame\n",
    "# geometry = [Polygon([(row['x1'], row['y1']), (row['x2'], row['y1']),\n",
    "#                 (row['x2'], row['y2']), (row['x1'], row['y2'])])\n",
    "#         for _, row in coords.iterrows()]\n",
    "\n",
    "# gdf_polygons = gpd.GeoDataFrame(geometry=geometry)\n",
    "\n",
    "# # Create a figure and axis\n",
    "# fig, ax = plt.subplots(figsize=(24, 15))\n",
    "\n",
    "# # Plot GeoDataFrames\n",
    "# gdf_T32TMT.plot(ax=ax, color='#3d5a80', edgecolor='black', alpha=0.5)\n",
    "# gdf_T32TMS.plot(ax=ax, color='#98c1d9', edgecolor='black', alpha=0.5)\n",
    "# gdf_T32TLS.plot(ax=ax, color='#e0fbfc', edgecolor='black', alpha=0.5)\n",
    "# gdf_T32TLT.plot(ax=ax, color='#293241', edgecolor='black', alpha=0.5)\n",
    "# get_bern_bbox().plot(ax=ax, color='#ee6c4d', edgecolor='black', alpha=0.5)\n",
    "# gdf_polygons.plot(ax=ax, color='black', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# ax.set_title('UTM-Tiles and Bern Bounding-Box')\n",
    "\n",
    "# # Create a custom legend using Line2D for GeoPandas plots\n",
    "# legend_elements = [\n",
    "#     Line2D([0], [0], color='#3d5a80', label='T32TMT'),\n",
    "#     Line2D([0], [0], color='#98c1d9', label='T32TMS'),\n",
    "#     Line2D([0], [0], color='#e0fbfc', label='T32TLS'),\n",
    "#     Line2D([0], [0], color='#293241', label='T32TLT'),\n",
    "#     Line2D([0], [0], color='#ee6c4d', label='Bern B-Box'),\n",
    "#     Line2D([0], [0], color='black',label='240m x 240m Polygons')\n",
    "# ]\n",
    "\n",
    "# # Add the legend outside the plot\n",
    "# ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ecc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tile data and save to dhf5 files\n",
    "tiles = ['T32TLS']#,'T32TLT','T32TMS','T32TMT']\n",
    "# tiles = ['T32TLT','T32TLS','T32TMT','T32TMS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# E:\\S2_Data_CH22\\T32TLS\\S2B_MSIL2A_20221225T103349_N0509_R108_T32TLS_20221225T114808.SAFE\\INSPIRE.xml -> gut \n",
    "# E:\\S2_Data_CH22\\T32TLT\\S2A_MSIL2A_20220812T103031_N0400_R108_T32TLT_20220812T182800.SAFE\\INSPIRE.xml -> gut\n",
    "# E:\\S2_Data_CH22\\T32TMS\\S2A_MSIL2A_20221127T102351_N0400_R065_T32TMS_20221127T140108.SAFE\\INSPIRE.xml -> gut\n",
    "# E:\\S2_Data_CH22\\T32TMT\\S2A_MSIL2A_20220603T102611_N0400_R108_T32TMT_20220603T170511.SAFE\\INSPIRE.xml -> gut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tile in tiles:\n",
    "# for tile in tiles:\n",
    "    print(f\"Start {tile}\")\n",
    "    coords = get_coords(tile,True)\n",
    "    data_dir = Path('E:/S2_Data_CH22/' + tile)\n",
    "    tile_paths = get_tile_folder_path(data_dir)\n",
    "    read_tile_data_from_safe(tile_paths,coords,tile)\n",
    "    print(f\"End {tile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_tile_data('T32TLS','data').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0225cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_tile_data('T32TMT','data').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate(tiles):\n",
    "        tile = read_tile_data(tiles[i])\n",
    "        tile_labels = read_tile_data(tiles[i],'gt')\n",
    "        tile_field_labels = read_tile_data(tiles[i],'gt_instance')\n",
    "\n",
    "        print(tile_labels.shape)\n",
    "        #TODO: change minimal t\n",
    "        save_tile_data(stack_sample_tiles(tile,12),'BernCrop',add_axis=False)\n",
    "        save_tile_data(stack_sample_tiles(tile_labels,None),'BernCrop','gt',add_axis=False)\n",
    "        save_tile_data(stack_sample_tiles(tile_field_labels,None),'BernCrop','gt_instance',add_axis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_tile_data('BernCrop','data').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d75c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_tile_data('BernCrop','gt').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_tile_data('BernCrop','gt_instance').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
